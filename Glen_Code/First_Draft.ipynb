{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "pn.extension('plotly')\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load API Keys from Environment Variables and Pull BTC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"glassnode_api\")\n",
    "type(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define crypto currencies to pull\n",
    "crypto_list = [\"BTC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Price URLs\n",
    "price_url = 'https://api.glassnode.com/v1/metrics/market/price_usd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price API Request\n",
    "btc_price_res = requests.get(price_url,\n",
    "                      params={'a': 'BTC',\n",
    "                              'i': '24h',\n",
    "                              'api_key': api_key})\n",
    "\n",
    "\n",
    "# Convert price to Pandas Dataframe, set index to time and clean up file\n",
    "btc_price_df = pd.read_json(btc_price_res.text, convert_dates=['t'])\n",
    "btc_price_df.columns = ['Date', 'BTC Price']\n",
    "btc_price_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTC Data Table Debugging Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_price_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTC Daily Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily change in price column\n",
    "btc_daily_price_pct_change = btc_price_df.pct_change(1)\n",
    "btc_daily_price_pct_change.columns = ['BTC Daily Price Change %']\n",
    "btc_daily_price_pct_change = btc_daily_price_pct_change.dropna()\n",
    "# btc_daily_price_pct_change\n",
    "btc_daily_price_pct_change.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTC Data Aggregating & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the different data frames into a list\n",
    "btc_frames = [btc_price_df, btc_daily_price_pct_change]\n",
    "\n",
    "# Concatenate all the dataframes into one\n",
    "btc_data = pd.concat(btc_frames, axis=1, join=\"outer\", ignore_index=False)\n",
    "btc_data['BTC Daily Price Change %'] = btc_data['BTC Daily Price Change %']*100\n",
    "btc_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DataFrame from CSV\n",
    "bitcoin_df = pd.read_csv(Path('DataNews_Bitcoin.csv'))\n",
    "bitcoin_df['Published Date'] = pd.to_datetime(bitcoin_df['Published Date'], exact = False, infer_datetime_format=True, format = '%Y/%m%d')\n",
    "for i in bitcoin_df.index:\n",
    "     bitcoin_df['Published Date'][i] = bitcoin_df['Published Date'][i].date()\n",
    "bitcoin_df.columns = ['Date', 'Title', 'Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize VADER Sentiment Analyzer\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download/Update the VADER Lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to store the sentiment scores in DataFrame\n",
    "btc_sentiments = []\n",
    "\n",
    "\n",
    "for i in bitcoin_df.index:\n",
    "    try:\n",
    "        text = bitcoin_df[\"Content\"][i]\n",
    "        date = bitcoin_df[\"Date\"][i]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "    \n",
    "        \n",
    "        btc_sentiments.append({\n",
    "            \"text\": text,\n",
    "            \"Date\": date,\n",
    "            \"compound\": compound,\n",
    "            \"positive\": pos,\n",
    "            \"negative\": neg,\n",
    "            \"neutral\": neu\n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "# Create DataFrame\n",
    "btc_df = pd.DataFrame(btc_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"text\", \"compound\", \"positive\", \"negative\", \"neutral\"]\n",
    "btc_df = btc_df[cols]\n",
    "\n",
    "btc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#btc_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive stats from the DataFrame\n",
    "#btc_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append daily BTC prices to Sentiment DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Date column to index\n",
    "btc_df['Date'] = pd.to_datetime(btc_df['Date'])\n",
    "btc_df = btc_df.set_index('Date')\n",
    "\n",
    "#btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_merged = pd.merge(\n",
    "    btc_df,\n",
    "    btc_data,\n",
    "    how='inner',\n",
    "    on='Date')\n",
    "\n",
    "btc_merged.dropna()\n",
    "btc_merged.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crude Visualizations\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set mulitple daily observations to a single mean\n",
    "btc_viz = btc_merged.groupby(pd.Grouper(freq='d')).mean().dropna(how='all')\n",
    "btc_viz_text = pd.DataFrame(btc_merged['text'].groupby('Date').apply(lambda texts: ' '.join(texts)))\n",
    "\n",
    "btc_viz_weekly = btc_merged.groupby(pd.Grouper(freq='w')).mean().dropna(how='all')\n",
    "btc_viz_monthly = btc_merged.groupby(pd.Grouper(freq='m')).mean().dropna(how='all')\n",
    "btc_viz_yearly = btc_merged.groupby(pd.Grouper(freq='y')).mean().dropna(how='all')\n",
    "\n",
    "btc_corr = btc_viz.drop(columns=['positive','negative','neutral'])\n",
    "\n",
    "btc_corr['lagprice'] = btc_corr['BTC Price'].shift(0)\n",
    "btc_corr['lagprice2'] = btc_corr['BTC Price'].shift(1)\n",
    "\n",
    "sns.heatmap(btc_corr.corr(), annot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text Column grouped by day\n",
    "btc_viz_text = pd.DataFrame(btc_merged['text'].groupby('Date').apply(lambda texts: ' '.join(texts)))\n",
    "# Concat text Column and Data Columns grouped by day\n",
    "#btc_viz_grouped = pd.concat([btc_viz_text, btc_viz], axis = 1, join = 'inner' )\n",
    "btc_viz_grouped = pd.merge(btc_viz_text, btc_viz, how = 'outer', left_on = 'Date', right_on = 'Date' )\n",
    "btc_viz_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Sentiment Score', color=color)\n",
    "ax1.plot(btc_viz['compound'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_xticklabels(ax1.get_xticks(), rotation = 90)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Price Change %', color=color)  \n",
    "ax2.plot(btc_viz['BTC Daily Price Change %'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a predictive Model with Vader\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in a binary classifier for positive and negative price changes\n",
    "btc_merged['target'] = np.where(btc_merged['BTC Daily Price Change %'] > 0, 1, 0)\n",
    "# Add in a binary classifier for positive and negative price changes in grouped dataframe\n",
    "btc_viz_grouped['target'] = np.where(btc_viz_grouped['BTC Daily Price Change %'] > 0, 1, 0)\n",
    "btc_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = btc_merged[\"text\"]\n",
    "y = btc_merged[\"target\"]\n",
    "\n",
    "# Split data into train & test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.scatter(btc_merged['positive'],btc_merged['negative'], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append sentiment back using indices\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions\n",
    "print(f\"Train: {train.shape[0]} rows and {train.shape[1]} columns\")\n",
    "print(f\"{train['target'].value_counts()}\\n\")\n",
    "print(f\"Test: {test.shape[0]} rows and {test.shape[1]} columns\")\n",
    "print(test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['neg', 'neu', 'pos', 'compound']] = train['text'].apply(analyzer.polarity_scores).apply(pd.Series)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['pos', 'neg', 'neu', 'compound']:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.distplot(train.query(\"target==1\")[var], bins=30, kde=False, \n",
    "                 color='blue', label='Positive')\n",
    "    sns.distplot(train.query(\"target==0\")[var], bins=30, kde=False, \n",
    "                 color='gray', label='Negative')\n",
    "    plt.legend()\n",
    "    plt.title(f'Histogram of {var} by true sentiment');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Predictive Model with RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tokenizer method from Keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "for token in list(tokenizer.word_index)[:10]:\n",
    "    print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "X_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast a sample numerical sequence with its text version\n",
    "print(\"**Text comment**\")\n",
    "print({X[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**Numerical sequence representation**\")\n",
    "print(X_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the pad size\n",
    "max_words = 100\n",
    "\n",
    "# Pad the sequences using the pad_sequences() method\n",
    "X_pad = pad_sequences(X_seq, padding = 'post', truncating = 'post')\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets using the encoded data\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement random oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# RandomOverSampler randomly duplicates minority class transactions\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_rnn, y_train_rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=280))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Comparison\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries from sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VADER - polarity model\n",
    "train['vader_polarity'] = np.where(train['pos']>train['neg'], 1, 0)\n",
    "target_names=['negative', 'positive']\n",
    "print(\"Classification Report for the VADER Sentiment Model using polarity scores\")\n",
    "print(classification_report(train['target'], \n",
    "                            train['vader_polarity'], \n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VADER - compound model\n",
    "train['vader_compound'] = np.where(train['compound']>0, 1, 0)\n",
    "print(\"Classification Report for the VADER Sentiment Model using compound scores\")\n",
    "print(classification_report(train['target'], \n",
    "                            train['vader_compound'], \n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(y_rnn_pred, y_test_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function we can call for all models\n",
    "def plot_cm(y_test, y_pred, target_names=['negative', 'positive'], \n",
    "            figsize=(5,3)):\n",
    "    \"\"\"Create a labelled confusion matrix plot.\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='BuGn', cbar=False, \n",
    "                ax=ax)\n",
    "    ax.set_title('Confusion matrix')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_xticklabels(target_names)\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_yticklabels(target_names, \n",
    "                       fontdict={'verticalalignment': 'center'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for VADER using polarity scores\n",
    "print(\"Confusion Matrix from the VADER model using polarity scores\")\n",
    "plot_cm(train['target'], train['vader_polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix from the VADER model using compound scores\")\n",
    "plot_cm(train['target'], train['vader_compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "plot_cm(y_test_rnn, y_rnn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Vader Accuracy - Polarity: %.2f\" % (accuracy_score(train['target'], train['vader_polarity'])))\n",
    "print(\"Vader Accuracy - Compound: %.2f\" % (accuracy_score(train['target'], train['vader_compound'])))\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - VADER Compound\n",
    "fpr_test_vader, tpr_test_vader, thresholds_test_vader = roc_curve(train['target'], train['vader_compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for VADER\n",
    "auc_test_vader = auc(fpr_test_vader, tpr_test_vader)\n",
    "auc_test_vader = round(auc_test_vader, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for VADER\n",
    "roc_df_test_vader = pd.DataFrame({\"FPR Test\": fpr_test_vader, \"TPR Test\": tpr_test_vader,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df_test_vader.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"red\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve - VADER(Compound) (AUC={auc_test_vader})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - VADER Compound\n",
    "fpr_test_vader, tpr_test_vader, thresholds_test_vader = roc_curve(train['target'], train['vader_polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for VADER\n",
    "auc_test_vader = auc(fpr_test_vader, tpr_test_vader)\n",
    "auc_test_vader = round(auc_test_vader, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for VADER\n",
    "roc_df_test_vader = pd.DataFrame({\"FPR Test\": fpr_test_vader, \"TPR Test\": tpr_test_vader,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df_test_vader.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"red\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve - VADER(Polarity) (AUC={auc_test_vader})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "test_predictions_rnn = model.predict(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - RNN LSTM Model\n",
    "fpr_test_rnn, tpr_test_rnn, thresholds_test_rnn = roc_curve(y_test_rnn, test_predictions_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for the RNN LSTM Model\n",
    "auc_test_rnn = auc(fpr_test_rnn, tpr_test_rnn)\n",
    "auc_test_rnn = round(auc_test_rnn, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for the RNN LSTM model\n",
    "roc_df_test_rnn = pd.DataFrame({\"FPR Test\": fpr_test_rnn, \"TPR Test\": tpr_test_rnn,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df_test_rnn.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"blue\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rnn})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:dlenv] *",
   "language": "python",
   "name": "conda-env-dlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
